23-07-11 12:53:47.548 - INFO:   name: sanitycheck_val
  phase: val
  gpu_ids: [1]
  path:[
    log: experiments/sanitycheck_val_230711_125342/logs
    checkpoint: experiments/sanitycheck_val_230711_125342/checkpoint
    resume_state: /home/zhuhe/HPE-with-Diffusion/experiments/sanitycheck_230711_005022/checkpoint/I90000_E19
    json_dt: /home/zhuhe/HPE-with-Diffusion/config/dt_val_results
    json_gt: /home/zhuhe/HPE-with-Diffusion/config/gt_val_results
    experiments_root: experiments/sanitycheck_val_230711_125342
  ]
  datasets:[
    train:[
      type: mscoco
      root: /home/zhuhe/HPE-with-Diffusion/data/coco/
      img_prefix: images/train2017
      ann: annotations/person_keypoints_train2017.json
      aug:[
        flip: True
        rot_factor: 45
        scale_factor: 0.25
        num_joints_half_body: 3
        prob_half_body: 0.3
      ]
    ]
    val:[
      type: mscoco
      root: /home/zhuhe/HPE-with-Diffusion/data/coco/
      img_prefix: images/val2017
      ann: annotations/person_keypoints_val2017.json
    ]
    test:[
      type: mscoco_det
      root: /home/zhuhe/HPE-with-Diffusion/data/coco/
      img_prefix: images/val2017
      det_file: /home/zhuhe/HPE-with-Diffusion/config/test_det_rcnn.json
      ann: annotations/person_keypoints_val2017.json
    ]
  ]
  data_preset:[
    type: simple
    sigma: 2
    num_joints: 17
    image_size: [256, 192]
    heatmap_size: [64, 48]
  ]
  model:[
    regressor:[
      num_layers: 50
    ]
    denoise_transformer:[
      dim: 2048
      num_time_embeds: 1
      num_image_embeds: 4
      num_pose_embeds: 1
      num_keypoints: 17
      casual_transformer:[
        depth: 12
        dim_head: 64
        heads: 12
        ff_mult: 4
        norm_out: True
        attn_dropout: 0.05
        ff_dropout: 0.05
        final_proj: True
        normformer: True
        rotary_emb: True
      ]
    ]
    diffusion:[
      condition_on_preds: True
    ]
    beta_schedule:[
      train:[
        schedule: linear
        n_timestep: 2000
        linear_start: 1e-06
        linear_end: 0.01
      ]
      val:[
        schedule: linear
        n_timestep: 2000
        linear_start: 1e-06
        linear_end: 0.01
      ]
    ]
  ]
  loss:[
    type: sanity_check
    regress: l1
  ]
  train:[
    batch_size: 32
    end_epoch: 270
    optimizer: adam
    lr: 0.001
    lr_factor: 0.1
    lr_step: [170, 200]
    val_freq: 1000
    save_checkpoint_freq: 5000
    print_freq: 50
    ema_scheduler:[
      step_start_ema: 5000
      update_ema_every: 1
      ema_decay: 0.9999
    ]
  ]
  test:[
    heatmap2coord: coord
    batch_size: 32
  ]
  wandb:[
    project_name: DiffHPE
    run_name: sanitycheck_val
  ]
  distributed: False
loading annotations into memory...
Done (t=3.08s)
creating index...
index created!
23-07-11 12:53:55.438 - INFO: Initial Dataset Finished
/home/zhuhe/.conda/envs/diffhpe/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/zhuhe/.conda/envs/diffhpe/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
loading annotations into memory...
Done (t=0.08s)
creating index...
index created!
Traceback (most recent call last):
  File "/home/zhuhe/HPE-with-Diffusion/main.py", line 72, in <module>
    diffusion = Model.create_model(opt)    # diffusion - DDPM
  File "/home/zhuhe/HPE-with-Diffusion/model/__init__.py", line 7, in create_model
    m = M(opt)  # initialize a DDPM model with opts
  File "/home/zhuhe/HPE-with-Diffusion/model/model.py", line 21, in __init__
    self.netG = self.set_device(self.netG)
  File "/home/zhuhe/HPE-with-Diffusion/model/base_model.py", line 39, in set_device
    x = x.to(self.device)
  File "/home/zhuhe/.conda/envs/diffhpe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 989, in to
    return self._apply(convert)
  File "/home/zhuhe/.conda/envs/diffhpe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/zhuhe/.conda/envs/diffhpe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/zhuhe/.conda/envs/diffhpe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 641, in _apply
    module._apply(fn)
  File "/home/zhuhe/.conda/envs/diffhpe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 664, in _apply
    param_applied = fn(param)
  File "/home/zhuhe/.conda/envs/diffhpe/lib/python3.9/site-packages/torch/nn/modules/module.py", line 987, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.